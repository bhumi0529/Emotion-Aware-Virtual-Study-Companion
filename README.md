# ğŸ“ Emotion-Aware Virtual Study Companion ğŸ’¡

This project is an intelligent emotion detection system designed to act as a **virtual study buddy**. It uses computer vision and machine learning to detect a user's facial emotion in real-time and offers **motivational or productivity tips** based on the detected emotion.

---

## ğŸš€ Features

- ğŸ˜ƒ Detects facial emotion in real-time using webcam
- ğŸ§  Trained CNN model on the FER-2013 emotion dataset
- ğŸ“¦ Uses OpenCV for face detection
- ğŸ’¬ Provides productivity/motivational tips for each emotion
- ğŸ“ Ideal for students to stay engaged and emotionally aware while studying

---

## ğŸ“ Project Structure

Emotion-Aware-Virtual-Study-Companion/
â”‚
â”œâ”€â”€ emotion_detector.py # Main app (webcam + prediction + tips)
â”œâ”€â”€ haarcascade_frontalface_default.xml # Face detection model (OpenCV)
â”œâ”€â”€ emotion_model.keras # Trained emotion detection model
â”œâ”€â”€ model/ # Folder storing trained models
â”œâ”€â”€ dataset/ # Dataset folder (optional if using FER-2013)
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Project documentation

## ğŸ› ï¸ Technologies Used

- Python ğŸ
- TensorFlow / Keras
- OpenCV
- NumPy
- Matplotlib (for training plots)

## ğŸ§  How It Works

1. The user runs `emotion_detector.py`
2. The webcam opens, and a face detection box appears
3. The system detects emotion from facial expressions
4. Based on the predicted emotion, a related tip is shown (e.g., stay calm, take a break, stay motivated)

## ğŸ“¸ Supported Emotions

- Angry
- Disgust
- Fear
- Happy
- Neutral
- Sad
- Surprise

---

## â–¶ï¸ How to Run

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/Emotion-Aware-Virtual-Study-Companion.git
cd Emotion-Aware-Virtual-Study-Companion
2. Create a virtual environment (optional)
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
3. Install dependencies
pip install -r requirements.txt
4. Run the emotion detector
python emotion_detector.py
ğŸ“ For Training the Model (Optional)
If you wish to retrain the model:
You can modify the number of epochs and dataset path inside the Emotion_model.ipynb

ğŸ“œ Credits
FER-2013 Dataset from Kaggle

Haar Cascade from OpenCV

Developed by [Bhumi] during AI/ML Training

ğŸ“Œ Future Improvements
Add a graphical UI using Tkinter or Streamlit

Log emotions over time for emotional awareness charts

Add speech-based interaction